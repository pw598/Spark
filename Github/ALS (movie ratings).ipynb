{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e16e465d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\ProgramData\\\\anaconda3\\\\Lib\\\\site-packages\\\\pyspark'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ee6c3f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 1.983048757799533\n",
      "+------+--------------------+\n",
      "|userId|     recommendations|\n",
      "+------+--------------------+\n",
      "|    20|[{22, 4.541135}, ...|\n",
      "|    10|[{7, 5.2663555}, ...|\n",
      "|     0|[{39, 4.815112}, ...|\n",
      "|     1|[{80, 4.130293}, ...|\n",
      "|    21|[{29, 5.1546144},...|\n",
      "|    11|[{23, 5.441157}, ...|\n",
      "|    12|[{27, 5.166915}, ...|\n",
      "|    22|[{85, 5.9985123},...|\n",
      "|     2|[{93, 5.137864}, ...|\n",
      "|    13|[{93, 3.269409}, ...|\n",
      "|     3|[{75, 5.4319606},...|\n",
      "|    23|[{49, 5.2146263},...|\n",
      "|     4|[{53, 4.8758783},...|\n",
      "|    24|[{90, 5.3957944},...|\n",
      "|    14|[{41, 5.009279}, ...|\n",
      "|     5|[{55, 4.159607}, ...|\n",
      "|    15|[{27, 4.877583}, ...|\n",
      "|    25|[{33, 3.9315107},...|\n",
      "|    26|[{75, 6.1195173},...|\n",
      "|     6|[{25, 5.1269073},...|\n",
      "+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------+--------------------+\n",
      "|movieId|     recommendations|\n",
      "+-------+--------------------+\n",
      "|     20|[{17, 4.5583105},...|\n",
      "|     40|[{2, 3.5505679}, ...|\n",
      "|     10|[{17, 3.7931275},...|\n",
      "|     50|[{23, 4.083418}, ...|\n",
      "|     80|[{26, 5.217221}, ...|\n",
      "|     70|[{14, 4.720014}, ...|\n",
      "|     60|[{22, 3.1877866},...|\n",
      "|     90|[{17, 5.459472}, ...|\n",
      "|     30|[{22, 4.87693}, {...|\n",
      "|      0|[{28, 2.5218966},...|\n",
      "|     31|[{12, 3.8635335},...|\n",
      "|     81|[{28, 5.0103846},...|\n",
      "|     91|[{2, 3.5245192}, ...|\n",
      "|      1|[{15, 3.8797574},...|\n",
      "|     41|[{14, 5.009279}, ...|\n",
      "|     61|[{17, 2.8318172},...|\n",
      "|     51|[{22, 5.0881114},...|\n",
      "|     21|[{26, 3.2111897},...|\n",
      "|     11|[{18, 3.8175132},...|\n",
      "|     71|[{25, 3.9225066},...|\n",
      "+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+------+--------------------+\n",
      "|userId|     recommendations|\n",
      "+------+--------------------+\n",
      "|    26|[{75, 6.1195173},...|\n",
      "|    19|[{98, 3.5913}, {2...|\n",
      "|    29|[{46, 5.004602}, ...|\n",
      "+------+--------------------+\n",
      "\n",
      "+-------+--------------------+\n",
      "|movieId|     recommendations|\n",
      "+-------+--------------------+\n",
      "|     65|[{23, 4.594759}, ...|\n",
      "|     26|[{15, 3.0361683},...|\n",
      "|     29|[{21, 5.1546144},...|\n",
      "+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql import Row\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(\"ALSExample\")\\\n",
    "        .getOrCreate()\n",
    "\n",
    "    lines = spark.read.text(\"sample_movielens_ratings.txt\").rdd\n",
    "    parts = lines.map(lambda row: row.value.split(\"::\"))\n",
    "    ratingsRDD = parts.map(lambda p: Row(userId=int(p[0]), movieId=int(p[1]),\n",
    "                                         rating=float(p[2]), timestamp=int(p[3])))\n",
    "    ratings = spark.createDataFrame(ratingsRDD)\n",
    "    (training, test) = ratings.randomSplit([0.8, 0.2])\n",
    "\n",
    "    # Build the recommendation model using ALS on the training data\n",
    "    # Note we set cold start strategy to 'drop' to ensure we don't get NaN evaluation metrics\n",
    "    als = ALS(maxIter=5, regParam=0.01, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\",\n",
    "              coldStartStrategy=\"drop\")\n",
    "    model = als.fit(training)\n",
    "\n",
    "    # Evaluate the model by computing the RMSE on the test data\n",
    "    predictions = model.transform(test)\n",
    "    evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n",
    "                                    predictionCol=\"prediction\")\n",
    "    rmse = evaluator.evaluate(predictions)\n",
    "    print(\"Root-mean-square error = \" + str(rmse))\n",
    "\n",
    "    # Generate top 10 movie recommendations for each user\n",
    "    userRecs = model.recommendForAllUsers(10)\n",
    "    # Generate top 10 user recommendations for each movie\n",
    "    movieRecs = model.recommendForAllItems(10)\n",
    "\n",
    "    # Generate top 10 movie recommendations for a specified set of users\n",
    "    users = ratings.select(als.getUserCol()).distinct().limit(3)\n",
    "    userSubsetRecs = model.recommendForUserSubset(users, 10)\n",
    "    # Generate top 10 user recommendations for a specified set of movies\n",
    "    movies = ratings.select(als.getItemCol()).distinct().limit(3)\n",
    "    movieSubSetRecs = model.recommendForItemSubset(movies, 10)\n",
    "\n",
    "    userRecs.show()\n",
    "    movieRecs.show()\n",
    "    userSubsetRecs.show()\n",
    "    movieSubSetRecs.show()\n",
    "\n",
    "    spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e257d964",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
